\chapter[Introduction]{Introduction}\label{cap_intro}
The rapid growth of high-performance computing and the advances in numerical techniques in the last two decades have provided an unprecedented opportunity to explore complex physical phenomena using large-scale spatio-temporal modeling and simulation.  At the same time, scientific community is leaving behind the traditional deterministic approach, which offers  point predictions with no associated uncertainty \cite{Johnstone2015};  to include Uncertainty Quantification (\textit{UQ}) as a common practice in their researches. 

Large-scale spatio-temporal simulations with quantified uncertainty enable scientists to make precise statements about the degree of confidence they have in their simulation-based predictions. These approaches find practical applicability in models for predicting the behavior of weather, hurricane forecasts \cite{Tobergte2013}, subsurface hydrology \cite{Baroni2014a}, geology \cite{Guerra2016}, nuclear reactor design, financial portfolios \cite{Chen2008}, and biological phenomena, just to name a few. They also allow to study physical phenomena that are impossible to assess experimentally, for example: simulate nuclear accidents, or the conditions that some spatial vehicle will find at landing in Mars, and so on. The success of these techniques has made them increasingly important tools for high impact predictions and decision making.

\textit{UQ}  includes different aspects that warranty the predictive fidelity of a numerical simulation, such as the uncertainty in the experimental data, which is used for defining the parameter values of a model; the propagation of uncertain  parameters through the model; and the choice of the model itself. \textit{UQ} is a complex process that covers the following main tasks: (i) uncertainty characterization \cite{Crespo2014}, also called model calibration \cite{Farrell2015a} or statistical inverse problem \cite{Estacio-Hiroms2012};  (ii) sensitivity analysis; (iii) forward problem or uncertainty propagation; and (iv) model selection.

This paper is focused on  \textit{forward propagation}, whose objective is to quantify the uncertainties in model output(s) propagated from uncertain inputs. The targets of \textit{forward propagation} analysis can be: (i) evaluate low-order moments ( i.e. mean and variance) of the outputs, (ii) evaluate the reliability of the outputs, and/or (iii) assess the complete probability distribution (\textit{PDF}) of the outputs.

When dealing with large-scale spatio-temporal models, a huge among of data is generated as a result of the simulation process. Indeed, on each spatio-temporal location $(s_{i},t_{j}) \in \mathcal{S} \times \mathcal{T}\subseteq\mathbb{R}^{3}\times\mathbb{R}$ , usually more than $10^4$ simulations are performed. Then, the size of the output dataset is in the order of $N_{s}\times N_{t}\times N_{sim}$, where: $N_{s}$ is the number of spatial locations, $N_{t}$ is the number of time steps, and $N_{sim}$ is the number of simulations.  An example of the volume of data generated by these simulations is given in the experimental section \ref{Experiments} of this paper, where the output dataset is about 2.4 TB. This turn \textit{forward propagation} in a data intensive problem.

Another important aspect, which is often not taken into account, is that the uncertainty need to be quantified in some way that can be used after, to answer questions that arise in the \textit{UQ} context. In that sense, assess the complete \textit {PDF} could be the best way to quantify uncertainty, because if you can find the \textit {PDF} that best fit the dataset with reasonably accurately, you can get all the statistical properties under one roof. At the same time, we can substitute the original data by the \textit {PDFs}, which represents a huge reduction in the volume of data to manipulate.

Contradictorily, statistical moments (e.g. mean and standard deviation) are possibly the most used ways to quantify the uncertainty, despite the fact that they doesn't have information about the manner in which the data are distributed \cite{Lampasi2006}. This is because of the difficulty to find the \textit{PDF} that best fit a dataset \cite{Karian2011},  even more, when dealing with large-scale spatio-temporal models where the \textit{PDF} needs to be derived on each spatio-temporal location, and therefore the  \textit{forward propagation} problem becomes time consuming and computationally intensive too.

However, the use of low order moments alone prevents us from making accurate analysis with respect to the uncertainty. They are not enough neither for the characterization nor for the quantification of the uncertainty, and questions such as:
\begin{itemize}
\item What is the uncertainty in the spatio-temporal region $\mathcal{S}_{i} \times \mathcal{T}_{j}$ associated to the \textit{QoI} 
$q_{k}$  and a computational model $\mathcal{M}_{m}$?
\item How to compare different spatio-temporal regions $\mathcal{S}_{i} \times \mathcal{T}_{j}$ with respect to the uncertainty? 
\item What is the less uncertain model from the set of models $\mathcal{M}={\mathcal{M}_{1},\mathcal{M}_{2},
....\mathcal{M}_{m}}$, to predict the value of a QoI $q_{k}$, over a spatio-temporal region $\mathcal{S}_{i} \times \mathcal{T}_{j}$?
\end{itemize}
can be poorly answered. So, we emphasize that only the characterization of the uncertainty by using the \textit{PDF} allows aware decisions.

A first effort to try to estimate the \textit{PDFs} on large-scale spatio-temporal simulations was done by \cite{Liu2018} {Ji et. al.} in \textbf{\textit{Parallel Computation of PDFs on Big Spatial Data Using Spark}}. They propose a new solution to efficiently compute the \textit{PDFs} in parallel using Spark, through three methods: data grouping, machine learning prediction and sampling. The main drawback of the proposed approach is that you should try many different distributions, to find the PDF that best fits the dataset on each specific spatio-temporal location. Another drawback is that, as we mentioned above, the uncertainty needs to be quantified in the way that facilitates its further use; and the heterogeneity of the functions used in the approach doesn't facilitate it. 

To face these challenges, in this paper we propose a general framework to quantify the uncertainty in large-scale spatio-temporal models. It uses a data-driven approach and combines the generalized lambda distribution (\textit{GLD}), clusters algorithms and information entropy, for helping researchers to answer the above questions and many others that arise in \textit{UQ} context. Our proposal provides a generally applicable and easy-to-use tool that supports the representation and analysis of uncertainty, as was suggested in the "\textit{Workshop on Quantification, Communication, and Interpretation of Uncertainty in Simulation and Data Science}" \cite{Tobergte2013}. 

In order to illustrate the use of the proposed framework, a case study is discussed. The main results obtained are: (i) the \textit{GLD} good fits for more than the 80 \% of the dataset, (ii) the use of the \textit{GLD} allows to include clustering algorithms to group the spatio-temporal locations with similar uncertainty, (iii) the centroids  of the clusters can be used as a faithful representation of the rest of the spatio-temporal locations, which significantly reduces the data corresponding to the simulation outputs, (iv) with the use of these centroids we can characterize the uncertainty in any spatio-temporal region as a mixture of \textit{GLDs}.

The rest of the paper is organized as follows: Section \ref{UQBackground} gives the theoretical foundations of \textit{UQ} and highlights some interesting aspects included in our proposal. Section \ref{materials_methods} describes the principal characteristics of the \textit{GLD} that make it suitable for this proposal. Section \ref{Approach} presents the proposed approach, the workflow we implement and some considerations of the implementation. Section \ref{Experiments} presents a use case and discusses the results. This use case allows us to explain our approach in the context of a real problem, which facilitates its understanding. Section \ref{RelatedWorks} covers the related works and finally, section \ref{Conclusions} concludes the paper and proposes some future works.

\section{Research Objectives}

\begin{tcolorbox}
The main objective of this thesis is the proposal of a new method to quantify the uncertainty in large-scale spatio-temporal models based on the Generalized Lambda Distribution (GLD).
\end{tcolorbox}

To achieve that goal the following research questions need to be answered:

\textbf{RQ1.} how to group the output of the UQ process based on the simillarity of the uncertainty?

\textbf{RQ2.} what is the uncertainty in some spatio-temporal locations not previously analysed?

\textbf{RQ3.} what is the uncertainty of an specific spatio-temporal region?

\textbf{RQ4.} how to compare two regions as a function of its uncertainty?

\textbf{RQ5.} what is the less uncertain model from a set of models?

\textbf{RQ1} and \textbf{RQ2} are answered in chapter \ref{cap:gld_clustering}, while \textbf{RQ3}, \textbf{RQ4} and \textbf{RQ5} are answered in chapter \ref{cap:our_approach}. In chapter \ref{cap:use_cases} all the questions are answered again for all the use cases.

\section{Highlights of the Dissertation}

\section{Organization of the Dissertation}

The structure of the remainder of this thesis is outlined for reference.

\textbf{Chapter 2} background of UQ.

\textbf{Chapter 3} Ji paper.

\textbf{Chapter 4} GLD.

\textbf{Chapter 5} GLD clustering and kriging.

\textbf{Chapter 6} Workflow.

\textbf{Chapter 7} Use cases.

\textbf{Chapter 8} Conclusions and future works.
